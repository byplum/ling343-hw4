[
  {
    "objectID": "li_homework4.html",
    "href": "li_homework4.html",
    "title": "Homework 4",
    "section": "",
    "text": "# install.packages(\"RedditExtractoR\")\nlibrary(RedditExtractoR)\nlibrary(tidytext)\nlibrary(tidyverse)\n\n\n1. Pull some posts from a subreddit - you can choose the subreddit and if you want to specify particular keywords. Use your text analysis skills to calculate and visualize the top words, excluding stopwords. Iâ€™m being deliberately a big vague about how many words - see what looks informative depending on how much you are looking at, the content, etc.\n\n# run this code interactively to save the rds file in your project folder\ntop_bb_urls <- find_thread_urls(subreddit=\"basketball\", sort_by=\"top\")\nwrite_rds(top_bb_urls, \"top_bb_urls.rds\")\n\n\n# this code will run when rendering to read in the rds file\ntop_bb_urls <- read_rds(\"top_bb_urls.rds\")\ntop_bb_words <- top_bb_urls |>\n  tibble() |>\n  unnest_tokens(word, text) |>\n  anti_join(stop_words) |>\n  count(word, sort = TRUE)\n\nJoining with `by = join_by(word)`\n\ntop_bb_words |>\n  head(20) |>\n  ggplot(aes(x = reorder(word, n), y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(x = \"Word\", y = \"Count\", title = \"Top Words in r/Basketball Posts\")\n\n\n\n\n\nTo practice working with lists, pull data on a specific user. It can be yourself if you like! Do a similar word frequency analysis based on their comments.\n\nRender the html version of the document and share it as a webpage (not just repository) using GitHub Pages, in your Homework 4 repository (from p13). If you did not sign up for the student plan on GitHub, you will have to make sure your repository public to do so. If you want a private repository, make sure it is shared with me as a collaborator.\n\n# run this code interactively to save the rds file in your project folder\njj_comments <- get_user_content(c(\"jamesjuett\"))[[1]]$comments\nwrite_rds(jj_comments, \"jj_comments.rds\")\n\n\njj_comments <- read_rds(\"jj_comments.rds\")\n\ntop_jj_words <- jj_comments |>\n  tibble() |>\n  unnest_tokens(word, comment) |>\n  anti_join(stop_words) |>\n  count(word, sort = TRUE)\n\nJoining with `by = join_by(word)`\n\ntop_jj_words |>\n  head(20) |>\n  ggplot(aes(x = reorder(word, n), y = n)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(x = \"Word\", y = \"Count\", title = \"Top Words in u/jamesjuett\")"
  }
]